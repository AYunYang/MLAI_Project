{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f94684-a05f-4237-93fa-e637d24de85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D ,Input , AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = (150,150)\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "def image_gen_w_aug(train_parent_directory, validate_parent_directory, test_parent_directory):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=20,  # Reduced rotation to 20 degrees\n",
    "        zoom_range=0.1,     # Reduced zoom range to 10%\n",
    "        width_shift_range=0.2,  # Reduced shift to 20%\n",
    "        height_shift_range=0.2, # Reduced shift to 20%\n",
    "        shear_range=0.1,    # Reduced shear range to 10%\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        brightness_range=[0.9, 1.1])\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_parent_directory,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        validate_parent_directory,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_parent_directory,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def model_output():\n",
    "    model = Sequential()\n",
    "\n",
    "    Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "    \n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    # Flatten and Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    " \n",
    "    model.add(Dense(128, activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax',kernel_regularizer=l2(0.001)))\n",
    "\n",
    "    return model\n",
    "\n",
    "train_dir = os.path.join('./datasets/train')\n",
    "test_dir = os.path.join('./datasets/test')\n",
    "val_dir = os.path.join('./datasets/validation')\n",
    "\n",
    "train_generator, validation_generator, test_generator = image_gen_w_aug(train_dir, val_dir, test_dir)\n",
    "\n",
    "model = model_output()\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=INITIAL_LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "# Learning rate reduction\n",
    "early_stop= EarlyStopping(monitor='val_loss',patience=10,verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[lr_scheduler,early_stop]\n",
    "    )\n",
    "\n",
    "\n",
    "# end Time\n",
    "end_time = time.time()\n",
    "# duration \n",
    "duration = end_time - start_time\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "tf.keras.models.save_model(model,'my_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bd614-a801-48cb-a30f-b586969f20e5",
   "metadata": {},
   "source": [
    "Changed pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e4893-f6f5-489c-b243-0dd7349ed714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12,5))       \n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Model Loss\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Convert duration to minutes and seconds\n",
    "duration_min, duration_sec = divmod(duration, 60)\n",
    "print(f'Total time taken to train the model: {int(duration_min)} minutes and {int(duration_sec)} seconds')\n",
    "print()\n",
    "# Print out the final accuracy values\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print()\n",
    "# Print out the final loss values\n",
    "print(f\"Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "print()\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce07c95-d9cd-4c69-84d4-af023511dbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9aef4-43b5-4ffe-9c53-5e1ddbcaf9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
