{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f94684-a05f-4237-93fa-e637d24de85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = (150,150)\n",
    "EPOCHS = 100\n",
    "BATCH_TRAIN_SIZE = 16\n",
    "BATCH_SIZE = 15\n",
    "INITIAL_LEARNING_RATE = 6.3e-5\n",
    "L2_REGULARIZE = 1e-3\n",
    "\n",
    "def image_gen_w_aug(train_parent_directory, validate_parent_directory, test_parent_directory):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1/255,\n",
    "        rotation_range=40,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_parent_directory,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_TRAIN_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        validate_parent_directory,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_parent_directory,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "def model_output():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150,150, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax', kernel_regularizer=l2(L2_REGULARIZE)))\n",
    "\n",
    "    return model\n",
    "\n",
    "train_dir = os.path.join('./datasets/train')\n",
    "test_dir = os.path.join('./datasets/test')\n",
    "val_dir = os.path.join('./datasets/validation')\n",
    "\n",
    "train_generator, validation_generator, test_generator = image_gen_w_aug(train_dir, val_dir, test_dir)\n",
    "\n",
    "model = model_output()\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=INITIAL_LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch = train_generator.samples // BATCH_TRAIN_SIZE\n",
    "\n",
    "\n",
    "# Learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=8, verbose=1, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=len(train_generator) + 1,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=1,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[lr_scheduler, early_stopping]\n",
    "    )\n",
    "\n",
    "\n",
    "# end Time\n",
    "end_time = time.time()\n",
    "# duration \n",
    "duration = end_time - start_time\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "tf.keras.models.save_model(model,'my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e4893-f6f5-489c-b243-0dd7349ed714",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Convert duration to minutes and seconds\n",
    "duration_min, duration_sec = divmod(duration, 60)\n",
    "print(f'Total time taken to train the model: {int(duration_min)} minutes and {int(duration_sec)} seconds')\n",
    "print()\n",
    "# Print out the final accuracy values\n",
    "print(f\"Final Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print()\n",
    "# Print out the final loss values\n",
    "print(f\"Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "print()\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2811d03-9e03-4883-b937-9d681ce4b087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c7528-c702-4907-ba4e-8235d7f53434",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
